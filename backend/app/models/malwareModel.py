import uuid
from datetime import datetime
from mongoengine import (
    Document,
    StringField,
    DateTimeField,
    ListField,
    DictField,
    FloatField,
    EmbeddedDocumentField,
    EmbeddedDocument,
    ReferenceField,
    ValidationError,
    connect,
    QuerySet,
    IntField
)
import logging
import mongoengine

# Disconnect and reconnect to MongoDB
mongoengine.disconnect()
MONGODB_URI = "mongodb://127.0.0.1:27017/maldna_db"
DB_NAME = "maldna_db"
mongoengine.connect(DB_NAME, host=MONGODB_URI)

# Logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# Helper function to ensure valid strings
def ensure_string(value, default='unknown'):
    """Ensure the value is a string and return default if None."""
    if value is None:
        return default
    return str(value) if isinstance(value, (str, bytes)) else str(value)

# Helper function for validating lists
def ensure_list(value, default=None):
    """Ensure the value is a list and return default if None."""
    return value if isinstance(value, list) else (default or [])

# Helper function for validating float fields
def ensure_float(value, default=0.0):
    """Ensure the value is a float and return default if None."""
    try:
        return float(value) if value is not None else default
    except (ValueError, TypeError):
        return default

# Helper function for validating dict fields
def ensure_dict(value, default=None):
    """Ensure the value is a dictionary and return default if None."""
    if value is None:
        return default or {}
    return value if isinstance(value, dict) else default or {}
# Update MalwareMetadata with validated static analysis results
class MalwareMetadata(Document):
    metadataid = StringField(primary_key=True, default=lambda: str(uuid.uuid4()))
    sample_id = StringField(required=True)
    filename = StringField(required=True)
    file_path = StringField(required=True)
    dna_referenceid = StringField(required=True)  # Ensure this is required
    file_hash = StringField()  # Adding the missing file_hash attribute
    os_version = StringField()
    architecture = StringField()
    country_origin = StringField()
    collection_method = StringField()
    threat_actor = StringField()
    detection_status = StringField(choices=["detected", "not_detected", "suspicious"])
    timestamp = DateTimeField(default=datetime.utcnow)
    opcodes = ListField(StringField())
    obfuscation_detected = StringField(choices=["obfuscated", "not_obfuscated", "unknown"], default="unknown")
    processing_status = StringField(choices=["pending", "completed", "failed"], default="pending")
    blockchain_status = StringField(choices=["verified", "unverified", "pending"], default="pending")
    blockchain_verified = StringField(choices=["verified", "unverified", "pending"], default="pending")

    # Static Analysis fields
    entropy = FloatField(min_value=0.0)
    file_sections = ListField(StringField())
    entry_point = StringField()
    packers_detected = ListField(StringField())

    # Replacing BooleanField with StringField
    is_packed = StringField(choices=["yes", "no", "unknown"], default="unknown")
    suspicious_strings = ListField(StringField())
    obfuscated_strings = ListField(StringField())
    embedded_urls = ListField(StringField())
    embedded_ips = ListField(StringField())
    file_version_info = StringField()
    company_name = StringField()
    product_name = StringField()
    file_version = StringField()
    original_filename = StringField()
    imports = ListField(StringField())
    exports = ListField(StringField())
    resources = ListField(StringField())
    dll_characteristics = ListField(StringField())
    import_hash = StringField()
    opcode_sequence = StringField()
    suspicious_opcode_patterns = ListField(StringField())

    # Replacing BooleanField with StringField for nopsled_detected
    nopsled_detected = StringField(choices=["yes", "no", "unknown"], default="unknown")

    virus_total_detection = DictField(default=lambda: {"total": 0, "positives": 0, "scan_date": None, "detection_names": []})
    file_hashes = DictField(default=lambda: {"md5": "", "sha1": "", "sha256": "", "sha512": "", "ssdeep": "", "tlsh": ""})
    anti_debugging_techniques = ListField(StringField())
    anti_vm_checks = ListField(StringField())
    self_modifying_code = StringField(choices=["yes", "no", "unknown"], default="unknown")
    code_injection_signatures = ListField(StringField())
    heuristic_score = FloatField()
    matched_heuristics = ListField(StringField())
    feature_vector = ListField(FloatField())
    vectorized_representation = ListField(FloatField())
    analyzed_at = DateTimeField()

    meta = {
        'indexes': [],
        'ordering': ['-timestamp'],
        "auto_create_index": False
    }

    @classmethod
    def get_objects(cls):
        return cls.objects
    
    @classmethod
    def fix_invalid_indexes(cls):
        try:
            db = cls._get_collection().database
            collection = db[cls._get_collection_name()]
            indexes = collection.index_information()
            for name, spec in indexes.items():
                if name != "_id_" and "_id" in dict(spec.get("key", [])):
                    logger.warning(f"‚ö†Ô∏è Dropping invalid _id index: {name}")
                    collection.drop_index(name)
        except Exception as e:
            logger.error(f"‚ùå Error fixing invalid indexes: {str(e)}")

# Update MalwareMetadata with validated static analysis results
def update_malware_metadata(metadata, sample_id):
    try:
        logger.info(f"üîç Searching for metadata with sample_id: {sample_id}")

        # Ensure all fields are properly populated
        company_name = ensure_string(metadata.get('company_name'))
        file_version = ensure_string(metadata.get('file_version'))
        packers_detected = ensure_list(metadata.get('packers_detected'))

        is_packed = ensure_string(metadata.get('is_packed'), "unknown")
        entropy = ensure_float(metadata.get('entropy'))
        suspicious_strings = ensure_list(metadata.get('suspicious_strings'))
        obfuscated_strings = ensure_list(metadata.get('obfuscated_strings'))
        embedded_urls = ensure_list(metadata.get('embedded_urls'))
        embedded_ips = ensure_list(metadata.get('embedded_ips'))
        file_version_info = ensure_string(metadata.get('file_version_info'))
        original_filename = ensure_string(metadata.get('original_filename'))
        imports = ensure_list(metadata.get('imports'))
        exports = ensure_list(metadata.get('exports'))
        resources = ensure_list(metadata.get('resources'))
        dll_characteristics = ensure_list(metadata.get('dll_characteristics'))
        import_hash = ensure_string(metadata.get('import_hash'))
        opcode_sequence = ensure_string(metadata.get('opcode_sequence'))
        suspicious_opcode_patterns = ensure_list(metadata.get('suspicious_opcode_patterns'))

        nopsled_detected = ensure_string(metadata.get('nopsled_detected'), "unknown")

        # Calculate the file hash if it's not provided
        file_hash = ensure_string(metadata.get('file_hash'))
        if not file_hash:
            file_hash = generate_file_hash(metadata.get('file_path'))  # Assuming file_path is available

        # Ensure dna_referenceid is available
        dna_referenceid = ensure_string(metadata.get('dna_referenceid'), "unknown")

        # Update MongoDB document with validated fields
        malware_metadata = MalwareMetadata.objects(sample_id=sample_id).first()
        if not malware_metadata:
            logger.error(f"‚ùå No metadata found for sample_id: {sample_id}")
            return {"error": f"Malware metadata not found for sample_id {sample_id}"}

        malware_metadata.update(
            set__company_name=company_name,
            set__file_version=file_version,
            set__packers_detected=packers_detected,
            set__is_packed=is_packed,
            set__entropy=entropy,
            set__suspicious_strings=suspicious_strings,
            set__obfuscated_strings=obfuscated_strings,
            set__embedded_urls=embedded_urls,
            set__embedded_ips=embedded_ips,
            set__file_version_info=file_version_info,
            set__original_filename=original_filename,
            set__imports=imports,
            set__exports=exports,
            set__resources=resources,
            set__dll_characteristics=dll_characteristics,
            set__import_hash=import_hash,
            set__opcode_sequence=opcode_sequence,
            set__suspicious_opcode_patterns=suspicious_opcode_patterns,
            set__nopsled_detected=nopsled_detected,
            set__file_hash=file_hash,  # Ensure file hash is updated
            set__dna_referenceid=dna_referenceid,  # Ensure dna_referenceid is updated
            set__processing_status="completed",
        )

        logger.info(f"‚úÖ Static Analysis Results Stored for sample_id: {sample_id}")
        
        # Perform blockchain verification after updating metadata
        blockchain_verification_result = update_blockchain_status(malware_metadata, "pending")

        return {
            "company_name": company_name,
            "file_version": file_version,
            "packers_detected": packers_detected,
            "is_packed": is_packed,
            "entropy": entropy,
            "suspicious_strings": suspicious_strings,
            "obfuscated_strings": obfuscated_strings,
            "blockchain_verification": blockchain_verification_result
        }
    except Exception as e:
        logger.error(f"‚ùå Error while updating metadata for sample_id {sample_id}: {str(e)}")
        return {"error": str(e)}

# Helper to generate file hash if needed
def generate_file_hash(file_path):
    hash_sha256 = hashlib.sha256()
    try:
        with open(file_path, "rb") as f:
            while chunk := f.read(4096):
                hash_sha256.update(chunk)
    except Exception as e:
        logger.error(f"‚ùå Error calculating file hash: {e}")
        return ""
    return hash_sha256.hexdigest()


class BehaviorLog(Document):
    sample_id = StringField(required=True)
    log_timestamp = DateTimeField(default=datetime.utcnow)
    log_type = StringField(choices=["network", "file", "process", "registry", "system"])
    severity = StringField(choices=["low", "medium", "high"])
    message = StringField()
    processed_by = StringField(default="MalDNA System")

    meta = {'indexes': ['sample_id', 'log_timestamp'],"auto_create_index": False}

# Update BehaviorLog using sample_id
def update_behavior_log(sample_id, log_type, severity, message):
    try:
        log = BehaviorLog(
            sample_id=sample_id,
            log_type=log_type,
            severity=severity,
            message=message
        )
        log.save()
        logger.info(f"Behavior log created for sample: {sample_id}")
        return {"message": "Behavior log created successfully"}
    except Exception as e:
        logger.error(f"‚ùå Error creating behavior log: {str(e)}")
        return {"error": str(e)}

class DeepLearningClassification(Document):
    classificationid = StringField(primary_key=True, default=lambda: str(uuid.uuid4()))
    sample_id = StringField(required=True)
    model_name = StringField()
    prediction = StringField()
    confidence_score = FloatField()
    classification_status = StringField(choices=["successful", "failed"], default="successful")
    timestamp = DateTimeField(default=datetime.utcnow)

    meta = {
        'indexes': ['classificationid', 'sample_id'], "auto_create_index": False
    }

    @classmethod
    def get_objects(cls):
        return cls.objects

class ProcessedFeatures(EmbeddedDocument):
    file_name = StringField(max_length=200)
    file_size = IntField(min_value=0)
    file_type = StringField(choices=[ 
        "PE", "ELF", "Mach-O", "APK", "Script", 
        "Shellcode", "Macro", "Firmware", "Other"
    ])
    file_hash = StringField(required=True, unique=True)
    entropy = FloatField(min_value=0.0)
    suspicious_strings = ListField(StringField())
    imported_libraries = ListField(StringField())
    behavior_summary = DictField()
    iocs = ListField(DictField(default=lambda: {"type": None, "value": None, "confidence": 0.0}))
    execution_method = StringField(choices=[ 
        "exploit", "social_engineering", "drive_by_download", 
        "user_interaction", "supply_chain"
    ])
    propagation_method = StringField(choices=[ 
        "email", "usb", "network", "removable_media", "cloud_service"
    ])
    processed_at = DateTimeField(default=datetime.utcnow)

    # Optional additional fields
    last_accessed = DateTimeField()
    last_modified = DateTimeField()
    source = StringField()  # Origin of the sample

class MalwareAnalysisResult(Document):
    malwareid = StringField(required=True)
    static_analysis = DictField()
    dynamic_analysis = DictField()
    hybrid_analysis = DictField()
    timestamp = DateTimeField(default=datetime.utcnow)

    meta = {
        "indexes": ["malwareid", "timestamp"],
        "ordering": ["-timestamp"],
        "auto_create_index": False
    }

class MalwareModel(Document):
    sample_id = StringField(primary_key=True, default=lambda: str(uuid.uuid4()))
    dna_referenceid = StringField(required=True)

    # File Info
    name = StringField(max_length=200)
    file_type = StringField(choices=["PE", "ELF", "Mach-O", "APK", "Script", "Shellcode", "Macro", "Firmware", "Other"])
    file_size = IntField(min_value=0)
    file_hash = StringField(required=True, unique=True)
    storage_location = StringField(default="uploads")
    blockchain_verified = StringField(choices=["verified", "unverified", "pending"], default="pending")

    # Status Tracking
    collected_at = DateTimeField(default=datetime.utcnow)
    processed_status = StringField(choices=["pending", "completed", "failed"], default="pending")
    analysis_status = StringField(choices=["pending", "completed", "error"], default="pending")
    analyzed_at = DateTimeField()

    # ML & Family Classification
    family_name = StringField()
    variant_info = DictField(default=lambda: {"version": None, "mutation_count": 0, "significant_changes": []})
    classification_score = FloatField(min_value=0.0, max_value=1.0, default=0.5)
    prediction = StringField(choices=["benign", "malicious", "suspicious"], default="suspicious")

    # Result Snapshots
    static_analysis = DictField(default=lambda: {"entropy": None, "suspicious_strings": [], "imported_libraries": [], "code_sections": {}})
    dynamic_analysis = DictField(default=lambda: {"behavior_summary": {}, "system_changes": [], "resource_usage": {}})
    hybrid_analysis = DictField(default=dict)
    hybrid_features = DictField(default=dict)

    # Execution Tracking
    api_calls = ListField(StringField())
    system_modifications = ListField(DictField())
    iocs = ListField(DictField(default=lambda: {"type": None, "value": None, "confidence": 0.0}))
    execution_method = StringField(choices=["exploit", "social_engineering", "drive_by_download", "user_interaction", "supply_chain"])
    propagation_method = StringField(choices=["email", "usb", "network", "removable_media", "cloud_service"])

    # Platform Info
    platform = StringField(choices=["windows", "linux", "android", "macos", "ios", "embedded", "cross_platform"])
    target_environments = ListField(StringField())

    # Risk & Threat Intelligence
    risk_score = FloatField(min_value=0.0, max_value=100.0, default=0.0)
    threat_level = StringField(choices=["low", "medium", "high", "critical"], default="low")

    # Blockchain Integration
    blockchain_verification = DictField(default=lambda: {
        "tx_id": "",
        "verified_status": "pending",
        "timestamp": None,
        "chain_id": "",
        "gas_used": 0,
        "malware_hash": "",
        "event_synced": False,
        "cross_chain_support": [],
        "reputation_oracle": ""
    })
    external_contract_refs = ListField(DictField(default=lambda: {
        "contract_address": "",
        "chain_id": "",
        "purpose": ""
    }))
    malware_dna = StringField()
    lineageid = StringField()
    mutation_history = ListField(DictField(default=lambda: {"mutation": None, "timestamp": None}))

    # Related Samples
    related_samples = ListField(StringField())
    reputation_score = FloatField(default=0.0)
    lineage_info = DictField()

    # Embedded & Reference Fields
    deep_learning_classification = ReferenceField(DeepLearningClassification)
    behavior_logs = ListField(ReferenceField(BehaviorLog))
    processed_features = EmbeddedDocumentField(ProcessedFeatures)
    malware_metadata = ReferenceField(MalwareMetadata)

    # Logs & Origin
    audit_log = ListField(DictField(default=lambda: {
        "timestamp": datetime.utcnow(),
        "status": "created",
        "notes": "Initial record",
        "by": "system"
    }))
    analysis_origin = StringField(choices=["automated", "manual", "ai", "hybrid"], default="automated")

    # System
    last_updated = DateTimeField(default=datetime.utcnow)

    meta = {
        "collection": "malware_samples",
        "indexes": [
            "sample_id",
            "file_hash",
            "analysis_status",
            "collected_at",
            "prediction"
        ],
        "ordering": ["-collected_at"],
        "auto_create_index": False
    }

    def clean(self):
        logger.info(f"üß™ Validating MalwareModel sample_id={self.sample_id}")

        if self.processed_status not in ["pending", "completed", "failed"]:
            raise ValidationError("Processed status must be one of 'pending', 'completed', or 'failed'.")

        if self.blockchain_verified not in ["verified", "unverified", "pending"]:
            raise ValidationError("Blockchain verified status must be one of 'verified', 'unverified', or 'pending'.")

        if self.file_size is not None and self.file_size < 0:
            raise ValidationError("File size must be non-negative.")

        if not (0.0 <= self.classification_score <= 1.0):
            raise ValidationError("Classification score must be between 0.0 and 1.0")

        if not (0.0 <= self.risk_score <= 100.0):
            raise ValidationError("Risk score must be between 0.0 and 100.0")

    @classmethod
    def fix_invalid_indexes(cls):
        try:
            db = cls._get_collection().database
            collection = db[cls._get_collection_name()]
            indexes = collection.index_information()
            for name, spec in indexes.items():
                if name == "_id_":
                    if any(k in spec for k in ["background", "unique", "sparse"]):
                        logger.warning(f"‚ö†Ô∏è Dropping malformed _id index: {name} due to unsupported options.")
                        collection.drop_index(name)
                    else:
                        logger.info(f"‚úÖ Valid system _id index: {name}")
                    continue

                if any(k in spec for k in ["background", "unique", "sparse"]):
                    logger.warning(f"‚ö†Ô∏è Dropping invalid index: {name} due to unsupported option(s) in spec: {spec}")
                    collection.drop_index(name)
        except Exception as e:
            logger.error(f"‚ùå Error fixing invalid indexes: {str(e)}")

    def save_metadata(self):
        logger.info(f"üíæ Saving MalwareModel metadata for sample_id={self.sample_id}")
        try:
            self.full_clean()
            self.save()
        except ValidationError as ve:
            logger.error(f"‚ö†Ô∏è Validation error while saving sample_id={self.sample_id}: {ve.to_dict()}")
            raise ve
        except Exception as e:
            logger.error(f"‚ùå Unexpected error saving metadata for sample_id={self.sample_id}: {str(e)}")
            raise e


